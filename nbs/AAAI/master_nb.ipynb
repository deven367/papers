{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master notebook\n",
    "> This is a master notebook to generate embeddings for a given book with all the methods in a single place\n",
    "\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting colab_ssh\n",
      "  Downloading colab_ssh-0.3.27-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: colab-ssh\n",
      "Successfully installed colab-ssh-0.3.27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "*{\n",
       "\toutline:none;\n",
       "}\n",
       "code{\n",
       "\tdisplay:inline-block;\n",
       "\tpadding:5px 10px;\n",
       "\tbackground: #444;\n",
       "\tborder-radius: 4px;\n",
       "\twhite-space: pre-wrap;\n",
       "\tposition:relative;\n",
       "\tcolor:white;\n",
       "}\n",
       ".copy-code-button{\n",
       "\tfloat:right;\n",
       "\tbackground:#333;\n",
       "\tcolor:white;\n",
       "\tborder: none;\n",
       "\tmargin: 0 0 0 10px;\n",
       "\tcursor: pointer;\n",
       "}\n",
       "p, li{\n",
       "\tmax-width:700px;\n",
       "}\n",
       ".choices{\n",
       "\tdisplay:flex;\n",
       "\tflex: 1 0 auto;\n",
       "}\n",
       ".choice-section{\n",
       "\tborder:solid 1px #555;\n",
       "\tborder-radius: 4px;\n",
       "\tmin-width:300px;\n",
       "\tmargin: 10px 15px 0 0;\n",
       "\tpadding: 0 15px 15px 15px ;\n",
       "}\n",
       ".button{\n",
       "\tpadding: 10px 15px;\n",
       "\tbackground:#333;\n",
       "\tborder-radius: 4px;\n",
       "\tborder:solid 1px #555;\n",
       "\tcolor:white;\n",
       "\tfont-weight:bold;\n",
       "\tcursor:pointer;\n",
       "}\n",
       ".pill{\n",
       "\tpadding:2px 4px;\n",
       "\tborder-radius: 100px;\n",
       "\tbackground-color:#e65858;\n",
       "\tfont-size:12px;\n",
       "\tfont-weight:bold;\n",
       "\tmargin: 0 15px;\n",
       "\tcolor:white;\n",
       "}\n",
       "</style>\n",
       "<details class=\"choice-section\">\n",
       "\t<summary style=\"cursor:pointer\">\n",
       "\t\t<h3 style=\"display:inline-block;margin-top:15px\">⚙️ Client machine configuration<span class=\"pill\">Required</span></h3>\n",
       "\t</summary>\n",
       "\t<p>Don't worry, you only have to do this <b>once per client machine</b>.</p>\n",
       "\t<ol>\n",
       "\t\t<li>Download <a href=\"https://developers.cloudflare.com/argo-tunnel/getting-started/installation\">Cloudflared (Argo Tunnel)</a>, then copy the absolute path of the cloudflare binary</li>\n",
       "\t\t<li>Now, you have to append the following to your SSH config file (usually under ~/.ssh/config), and make sure you replace the placeholder with the path you copied in Step 1:</li>\n",
       "\t</ol>\n",
       "\t<code>Host *.trycloudflare.com\n",
       "\tHostName %h\n",
       "\tUser root\n",
       "\tPort 22\n",
       "\tProxyCommand &ltPUT_THE_ABSOLUTE_CLOUDFLARE_PATH_HERE&gt access ssh --hostname %h\n",
       "\t</code>\n",
       "</details>\n",
       "<div class=\"choices\">\n",
       "\t<div class=\"choice-section\">\n",
       "\t\t<h4>SSH Terminal</h4>\n",
       "\t\t<p>To connect using your terminal, type this command:</p>\n",
       "\t\t<code>ssh cj-declined-viewers-products.trycloudflare.com</code>\n",
       "\t</div>\n",
       "\t<div class=\"choice-section\">\n",
       "\t\t<h4>VSCode Remote SSH</h4>\n",
       "\t\t<p>You can also connect with VSCode Remote SSH (Ctrl+Shift+P and type \"Connect to Host...\"). Then, paste the following hostname in the opened command palette:</p>\n",
       "\t\t<code>cj-declined-viewers-products.trycloudflare.com</code>\n",
       "\t</div>\n",
       "</div>\n",
       "\n",
       "<script>\n",
       "// Copy any string\n",
       "function fallbackCopyTextToClipboard(text) {\n",
       "  var textArea = document.createElement(\"textarea\");\n",
       "  textArea.value = text;\n",
       "  \n",
       "  // Avoid scrolling to bottom\n",
       "  textArea.style.top = \"0\";\n",
       "  textArea.style.left = \"0\";\n",
       "  textArea.style.position = \"fixed\";\n",
       "\n",
       "  document.body.appendChild(textArea);\n",
       "  textArea.focus();\n",
       "  textArea.select();\n",
       "\n",
       "  try {\n",
       "    var successful = document.execCommand('copy');\n",
       "    var msg = successful ? 'successful' : 'unsuccessful';\n",
       "    console.log('Fallback: Copying text command was ' + msg);\n",
       "  } catch (err) {\n",
       "    console.error('Fallback: Oops, unable to copy', err);\n",
       "  }\n",
       "\n",
       "  document.body.removeChild(textArea);\n",
       "}\n",
       "\n",
       "// Show the copy button with every code tag\n",
       "document.querySelectorAll('code').forEach(function (codeBlock) {\n",
       "\tconst codeToCopy= codeBlock.innerText;\n",
       "\tvar pre = document.createElement('pre');\n",
       "\tpre.innerText = codeToCopy;\n",
       "    var button = document.createElement('button');\n",
       "    button.className = 'copy-code-button';\n",
       "    button.type = 'button';\n",
       "    button.innerText = 'Copy';\n",
       "\tbutton.onclick = function(){\n",
       "\t\tfallbackCopyTextToClipboard(codeToCopy);\n",
       "\t\tbutton.innerText = 'Copied'\n",
       "\t\tsetTimeout(()=>{\n",
       "\t\t\tbutton.innerText = 'Copy'\n",
       "\t\t},2000)\n",
       "\t}\n",
       "\tcodeBlock.children = pre;\n",
       "\tcodeBlock.prepend(button)\n",
       "});\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install colab_ssh --upgrade\n",
    "from colab_ssh import launch_ssh_cloudflared, init_git_cloudflared\n",
    "launch_ssh_cloudflared(password=\"mypassword\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'InferSent'...\n",
      "remote: Enumerating objects: 259, done.\u001b[K\n",
      "remote: Total 259 (delta 0), reused 0 (delta 0), pack-reused 259\u001b[K\n",
      "Receiving objects: 100% (259/259), 424.15 KiB | 7.44 MiB/s, done.\n",
      "Resolving deltas: 100% (135/135), done.\n",
      "\u001b[K     |████████████████████████████████| 85 kB 3.1 MB/s \n",
      "\u001b[K     |████████████████████████████████| 4.7 MB 31.6 MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 53.1 MB/s \n",
      "\u001b[K     |████████████████████████████████| 101 kB 12.7 MB/s \n",
      "\u001b[K     |████████████████████████████████| 596 kB 60.9 MB/s \n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 54.8 MB/s \n",
      "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a18848d3644994b6dc3a1b661708f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57b5172cadf4314bd229e4f38258920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819721782f9f4803b527fc42eb3f5e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.99k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be48f173e3b471f86fd3fc13c738261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/550 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c65e40fd4346e5bbe7f8ad9029961d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd7d5bf0d244323915e55f86a523241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5e3b2cb4bc433cb142b0dc0fb8d532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3da99c932143ad9774c417ba005edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8f22db2c764b40972545022b381a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea66156a86e426ca537900382b45de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/450 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268b4e70b7df4136be14a2e501435c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae517078e5d466bae404f895a7ef392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61b86f5284b45a19c224c7a62ee5c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/748 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c31625fa7004df0bce80c81bdced4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccee6fc35872450a88356f91c95dca32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a2fcd08805481587baf389b48420ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6876545f36a94a4ca3cfb40cbd5ecfa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2994caf327d14999b27168cd26276f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62e2024da7849f0846265c728a3427a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ff75dc099b4d5f942db52b3f54a6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844829fd2b88414dba726011c9b2c890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a7420e6df84a608239e5d15c801b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c717ac6fabc34cd1a5939410930dd212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5168e9a9f7c8402aa7acce7616bc9096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1a8a8835bd456fae6ca55b63604788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/335 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2e5b3d073f4e68b9114975b875177d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083a3a67dc174b5895598e415f0af44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33456eefdd1a49a08823d88ac11a3819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6f5b7980a2446baa45cb4e02353a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d596988fd104f3c813d8764c62d7c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e88e78560e4d309e9a2b1e00864658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2b3d6c4ff74e0ab0b3a33128d50cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648f7bd2440845d29602b8a8fc58eb32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c08b020bc74d7091d743b24b030fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57112e55485f45efa94d0310225907da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f276570e9e5a4deba1dc330187bb2b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60c88d8c2834964a557a82b6d50bd3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5eb8880fb604fdabee397632b490e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e93b9ae2f954553af4c62f6af16b787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c098ed1922ad482696c9ab0b9f2e1d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d038e4124c29428b8bf2202372952258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e4e3e7647944b6b8b0aa9624b662cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/391 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5047d3693af549199ce0df30875cfd3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.45k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40882bae010541c6821bb381dd6073a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/547 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ac607e0ba8408faa885494412cdceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8040303e7084dfdac8abc9d4f4e0125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6056019e2a4cd6922f46b5d88bf83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708b4113c6c043e2ba406bcd93e67f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/54.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda341c604674bd6ae5eafa0fd5df92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/johngiorgi_declutr-small. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/johngiorgi_declutr-small were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ad3d8f4de74fb397d9a0344dfcd136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/391 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2f784e65c04ab59a53776db7e30b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360cfbdc6c0e469bb22fde89c0ab8348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/548 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6291bbb3bc074eb3857f09044bf98cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08248ba317a54b668b780c49bec37cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2219eef9e49940a9820beff3d029d632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a004117c9048f1b7a68a7de8a418ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/54.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f89b083a4764de293ba05a5ee1af51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/johngiorgi_declutr-base. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/johngiorgi_declutr-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/InferSent.git\n",
    "\n",
    "!pip install -U sentence-transformers --quiet\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model_distil = SentenceTransformer('distilbert-base-nli-mean-tokens', device='cuda')\n",
    "model_robeta = SentenceTransformer('roberta-large-nli-stsb-mean-tokens', device='cuda')\n",
    "model_mpnet = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device='cuda')\n",
    "small = SentenceTransformer(\"johngiorgi/declutr-small\", device='cuda')\n",
    "base = SentenceTransformer(\"johngiorgi/declutr-base\", device='cuda')\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "model_use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_embeddings(sentences, fname):\n",
    "    embeddings = np.asarray(small(sentences, batch_size=128))\n",
    "    temp = f'{fname.stem}_dcltr_sm.npy'\n",
    "    np.save(temp, embeddings)\n",
    "    del embeddings\n",
    "\n",
    "def base_embeddings(sentences, fname):\n",
    "    embeddings = np.asarray(base(sentences, batch_size=128))\n",
    "    temp = f'{fname.stem}_dcltr_base.npy'\n",
    "    np.save(temp, embeddings)\n",
    "    del embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from InferSent import models\n",
    "import InferSent\n",
    "def if_glove(sentences, fname):\n",
    "    # from models import InferSent\n",
    "    MODEL_PATH = '/content/drive/MyDrive/infersent/encoder/infersent1.pkl'\n",
    "    params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                    'pool_type': 'max', 'dpout_model': 0.0, 'version': 1}\n",
    "    model = models.InferSent(params_model)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "    # Keep it on CPU or put it on GPU\n",
    "    use_cuda = True\n",
    "    model_glove = model.cuda() if use_cuda else model\n",
    "    \n",
    "    W2V_PATH = '/content/drive/MyDrive/infersent/glove.840B.300d.txt'\n",
    "    model_glove.set_w2v_path(W2V_PATH)\n",
    "    model_glove.build_vocab_k_words(K=100000)\n",
    "    embeddings = model_glove.encode(sentences, bsize=64, tokenize=False, verbose=True )\n",
    "    temp = f'{fname.stem}_if_glove.npy'\n",
    "    np.save(temp, embeddings)\n",
    "    del embeddings\n",
    "\n",
    "def if_ft(sentences, fname):\n",
    "    MODEL_PATH = '/content/drive/MyDrive/infersent/encoder/infersent2.pkl'\n",
    "    params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                    'pool_type': 'max', 'dpout_model': 0.0, 'version': 2}\n",
    "    model = models.InferSent(params_model)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "    # Keep it on CPU or put it on GPU\n",
    "    use_cuda = True\n",
    "    model_fasttext = model.cuda() if use_cuda else model\n",
    "    # If infersent1 -> use GloVe embeddings. If infersent2 -> use InferSent embeddings.\n",
    "    W2V_PATH = '/content/drive/MyDrive/infersent/crawl-300d-2M.vec'\n",
    "    model_fasttext.set_w2v_path(W2V_PATH)\n",
    "    model_fasttext.build_vocab_k_words(K=100000)\n",
    "    embeddings = model_fasttext.encode(sentences, bsize=64, tokenize=False, verbose=True )\n",
    "    temp = f'{fname.stem}_if_FT.npy'\n",
    "    np.save(temp, embeddings)\n",
    "    del embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_trans(sentences, fname):\n",
    "    embeddings = np.asarray(model_distil.encode(sentences, batch_size=128 ))\n",
    "    temp = f'{fname.stem}_distil.npy'\n",
    "    np.save(temp, embeddings)\n",
    "    del embeddings\n",
    "\n",
    "    f2 = np.asarray(model_robeta.encode(sentences, batch_size=128))\n",
    "    temp = f'{fname.stem}_roberta.npy'\n",
    "    np.save(temp, f2)\n",
    "    del f2\n",
    "\n",
    "    f2 = np.asarray(model_mpnet.encode(sentences, batch_size=128))\n",
    "    temp = f'{fname.stem}_mpnet.npy'\n",
    "    np.save(temp, f2)\n",
    "    del f2\n",
    "\n",
    "    embeddings = np.asarray(small.encode(sentences, batch_size=128))\n",
    "    temp = f'{fname.stem}_dcltr_sm.npy'\n",
    "    np.save(temp, embeddings)\n",
    "    del embeddings\n",
    "\n",
    "    embeddings = np.asarray(base.encode(sentences, batch_size=128))\n",
    "    temp = f'{fname.stem}_dcltr_base.npy'\n",
    "    np.save(temp, embeddings)\n",
    "    del embeddings\n",
    "\n",
    "def use_embed(sentences, fname):\n",
    "    final = np.asarray(model_use(sentences))\n",
    "    temp = f'{fname.stem}_use.npy'\n",
    "    np.save(temp, final)\n",
    "    del final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |█▍                              | 10 kB 25.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██▉                             | 20 kB 8.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 30 kB 3.6 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 40 kB 4.6 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 51 kB 4.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 61 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 71 kB 5.5 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 81 kB 4.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 92 kB 4.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 102 kB 3.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 112 kB 3.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 122 kB 3.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 133 kB 3.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▌            | 143 kB 3.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 153 kB 3.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 163 kB 3.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 174 kB 3.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 184 kB 3.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 194 kB 3.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 204 kB 3.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 215 kB 3.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 225 kB 3.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 235 kB 3.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 235 kB 3.8 MB/s \n",
      "\u001b[?25h  Building wheel for clean-plot (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/deven367/clean_plot.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from clean_plot.core import get_data\n",
    "from clean_plot.functions import split_by_newline\n",
    "from fastcore.xtras import globtastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) ['/content/txt/heart of darkness_cleaned.txt']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = globtastic('/content/txt', file_glob='*_cleaned.txt', recursive=False)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all(sentences, fname):\n",
    "    if_glove(sentences, fname)\n",
    "    if_ft(sentences, fname)\n",
    "\n",
    "    sent_trans(sentences, fname)\n",
    "\n",
    "    use_embed(sentences, fname)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on heart of darkness_cleaned\n",
      "Vocab size : 100000\n",
      "Nb words kept : 35491/42770 (83.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/InferSent/models.py:207: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sentences = np.array(sentences)[idx_sort]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed : 1174.6 sentences/s (gpu mode, bsize=64)\n",
      "Vocab size : 100000\n",
      "Nb words kept : 36156/42770 (84.5%)\n",
      "Speed : 2227.6 sentences/s (gpu mode, bsize=64)\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for f in files:\n",
    "    f = Path(f)\n",
    "    print(f'working on {f.stem}')\n",
    "    data = split_by_newline(get_data(f))\n",
    "    new_path = Path(f'/content/{f.stem}')\n",
    "    new_path.mkdir(exist_ok = True)\n",
    "    os.chdir(new_path)\n",
    "    generate_all(data, f)\n",
    "    print('-'*45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /content/Laughter_An_Essay_on_the_Meaning_of_the_Comic_cleaned/ /content/drive/MyDrive/AAA_Thesis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /content/A_Modest_Proposal_cleaned/ /content/drive/MyDrive/AAA_Thesis/\n",
    "!cp -r /content/A_Study_in_Scarlet_cleaned/ /content/drive/MyDrive/AAA_Thesis/\n",
    "!cp -r /content/Adventures_of_Huckleberry_Finn_cleaned/ /content/drive/MyDrive/AAA_Thesis/\n",
    "!cp -r /content/Dragons_and_Cherry_Blossoms_cleaned/ /content/drive/MyDrive/AAA_Thesis/\n",
    "!cp -r /content/Little_Women_by_Louisa_May_Alcott_cleaned/ /content/drive/MyDrive/AAA_Thesis/\n",
    "\n",
    "!cp -r /content/Ruth_of_the_USA_by_Edwin_Balmer_cleaned/ /content/drive/MyDrive/AAA_Thesis/\n",
    "!cp -r /content/The_Catspaw_cleaned/ /content/drive/MyDrive/AAA_Thesis/\n",
    "!cp -r /content/The_Hound_of_the_Baskervilles_cleaned/ /content/drive/MyDrive/AAA_Thesis/\n",
    "!cp -r /content/The_Scarlet_Letter_cleaned/ /content/drive/MyDrive/AAA_Thesis/\n",
    "!cp -r /content/The_Sons_of_Japheth_cleaned/ /content/drive/MyDrive/AAA_Thesis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /content/picture_of_dorian_gray_cleaned/ /content/drive/MyDrive/AAA_Thesis/\n",
    "!cp -r /content/siddartha_cleaned/ /content/drive/MyDrive/AAA_Thesis/\n",
    "!cp -r /content/metamorphosis_cleaned /content/drive/MyDrive/AAA_Thesis/\n",
    "!cp -r /content/a_christmas_carol_cleaned /content/drive/MyDrive/AAA_Thesis\n",
    "!cp -r /content/the_prophet_cleaned /content/drive/MyDrive/AAA_Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /content/heart_of_darkness_cleaned /content/drive/MyDrive/AAA_Thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul  3 20:23:50 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   54C    P0    28W /  70W |   8878MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15M\t/content/drive/MyDrive/AAA_Thesis/A_Modest_Proposal/\n"
     ]
    }
   ],
   "source": [
    "!du -sh /content/drive/MyDrive/AAA_Thesis/A_Modest_Proposal/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
